spawn_objects(object_choice, coordinates=[1.4,1.0,0.95], color, name)
  Returns: status, message, object{name,type,pose,color}
  Example: spawn_objects("spoon",[1.0,0.5,0.9],"blue","my_spoon")

move_robot(coordinates=[0,0,0])
  Returns: status, message, coordinates
  Example: move_robot([0,1,0])

pickup_and_place(object_name, target_location=[1.4,1.0,0.95], arm)
  Returns: status, message, object, target_location, arm_used
  Example: pickup_and_place("cereal",[1.4,0.2,0.95],"right")

robot_perceive(perception_area)
  Returns: status, message, perceived_objects[list{name,type,pose}]
  Example: robot_perceive("sink")

transport_object(object_name, target_location, arm)
  Returns: status, message, object, target_location, arm_used
  Example: transport_object("milk",[1.2,0.8,0.95],"left")

get_camera_images(target_distance=2.0)
  Returns: status, message, images{color_image,depth_image,segmentation_mask}
  Example: get_camera_images(1.5)

get_enhanced_camera_images(target_distance=2.0)
  Returns: status, message, images{color_image,depth_image,segmentation_mask}
  Example: get_enhanced_camera_images(2.5)

get_placement_surfaces(surface_type)
  Returns: status, message, surfaces{surface_name:{description,position,dimensions,recommended_for}}
  Example: get_placement_surfaces("kitchen")

spawn_in_area(object_choice, surface_name, color, name, offset_x, offset_y)
  Returns: status, message, object{name,type,pose,color}
  Example: spawn_in_area("cereal","kitchen_island_surface","red","test_cereal_1",0.1,0.1)

pick_and_place_on_surface(object_name, surface_name, offset_x, offset_y, arm)
  Returns: status, message, object, surface, position, arm_used
  Example: pick_and_place_on_surface("cereal1","kitchen_island_surface",0.1,0.1,"right")

calculate_object_distances(source_object, target_objects, exclude_types=[floor,wall,ceiling,ground])
  Returns: distances (either per target or all‑pairs)
  Example: calculate_object_distances("bowl",["spoon","cereal"])

look_at_object(obj_name)
  Returns: status, message
  Example: look_at_object("cereal")

detect_object(object_name, location)
  Returns: status, message, objects[list{name,type,position,color}]
  Example: detect_object("milk")

move_and_rotate(location, angle)
  Returns: status, message, position, orientation
  Example: move_and_rotate([0,0,0],60)

move_torso(position=low|high)
  Returns: status, message, position
  Example: move_torso("low")

calculate_relative_distances(object_name_1,object_name_2)
  Returns: status, object_1, object_2, dx, dy, dz, euclidean
  Example: calculate_relative_distances("cup","plate")

get_robot_pose()
  Returns: status, position, orientation
  Example: get_robot_pose()

park_arms(arm=left|right|both)
  Returns: status, message, arm
  Example: park_arms("both")

Rules on using the commands
IF user asks to “spawn” or “create” an object at coordinates -> spawn_objects(object_choice,coordinates,color,name); e.g. spawn_objects("spoon",[1.0,0.5,0.9],"blue","my_spoon")
IF user asks to “spawn” or “create” an object on a surface -> spawn_in_area(object_choice,surface_name,color,name,offset_x,offset_y); e.g. spawn_in_area("cereal","kitchen_island_surface","red","test_cereal_1",0.1,0.1)
IF user asks to move the robot to specific coordinates -> move_robot(coordinates); e.g. move_robot([0,1,0])
IF user asks to pick up an object and place it elsewhere using coordinates -> pickup_and_place(object_name,target_location,arm); e.g. pickup_and_place("cereal",[1.4,0.2,0.95],"right")
IF user asks to pick up an object and place it on a surface -> pick_and_place_on_surface(object_name,surface_name,offset_x,offset_y,arm); e.g. pick_and_place_on_surface("cereal1","kitchen_island_surface",0.1,0.1,"right")
IF user asks “what do you see” or to scan an area -> robot_perceive(perception_area); e.g. robot_perceive("table")
IF user asks to carry an object from A to B -> transport_object(object_name,target_location,arm); e.g. transport_object("milk",[1.2,0.8,0.95],"left")
IF user asks for raw camera images -> get_camera_images(target_distance); e.g. get_camera_images(1.5)
IF user asks for enhanced camera visuals -> get_enhanced_camera_images(target_distance); e.g. get_enhanced_camera_images(2.5)
IF user asks for available surfaces or where to place objects -> get_placement_surfaces(surface_type); e.g. get_placement_surfaces("kitchen")
IF user asks “how far is X from Y” or distance between objects (one-to-many or all-pairs) -> calculate_object_distances(source_object,target_objects,exclude_types); e.g. calculate_object_distances("bowl",["spoon"],["floor","wall","ceiling","ground"])
IF user asks for the component-wise or Euclidean distance between two objects -> calculate_relative_distances(object_name_1,object_name_2); e.g. calculate_relative_distances("cup","plate")
IF user asks the robot to focus or look at an object -> look_at_object(obj_name); e.g. look_at_object("cereal")
IF user asks to find or detect objects -> detect_object(object_name,location); e.g. detect_object("milk","sink")
IF user gives both a new position and orientation -> move_and_rotate(location,angle); e.g. move_and_rotate([0,0,0],60)
IF user asks to raise or lower its torso -> move_torso(position); e.g. move_torso("low")
IF user asks to stow or park its arms -> park_arms(arm); e.g. park_arms("both")
IF user asks for the robot's current pose or location -> get_robot_pose(); e.g. get_robot_pose()

// --- Differences between similar commands ---
- spawn_objects vs spawn_in_area: spawn_objects uses explicit coordinates; spawn_in_area uses a named surface and optional offsets for semantic placement.
- pickup_and_place vs pick_and_place_on_surface: pickup_and_place uses explicit coordinates; pick_and_place_on_surface uses a named surface and offsets.
- calculate_object_distances vs calculate_relative_distances: calculate_object_distances is for one-to-many or all-pairs; calculate_relative_distances is for a single pair with dx, dy, dz, and Euclidean distance.

// Parameter notes: Optional parameters are shown with defaults where applicable. Surface names like "kitchen_island_surface" can be listed using get_placement_surfaces.
// If a surface or object is not found, the API will return an error message in the response.
// Always provide as much context as possible for the agent to infer the correct command.

